"""
Sidebar Chat Component
Clean Architecture: Presentation Layer
Phase E: AI Agentic Control Integration
"""
import streamlit as st
import logging
from typing import Optional

from src.domain.chat.entities import ContextData
from src.domain.chat.actions import ActionExecutionResult
from src.services.chat.chat_service import ChatService
from src.services.chat.action_executor import ActionExecutor
from src.infrastructure.external.gemini_client import GeminiClient, MockLLMClient

logger = logging.getLogger(__name__)


def _get_stock_listing() -> dict:
    """ì¢…ëª© ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ActionExecutorìš©)"""
    # session_stateì—ì„œ ê°€ì ¸ì˜¤ê±°ë‚˜ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    stock_list = st.session_state.get('active_stock_list', {})
    
    # ì—­ë§¤í•‘ë„ ì¶”ê°€ (ì¢…ëª©ëª… -> ì¢…ëª©ì½”ë“œ)
    if not stock_list:
        # ê¸°ë³¸ ì¢…ëª© (ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬)
        return {}
    
    # {ì¢…ëª©ëª…: ì¢…ëª©ì½”ë“œ} -> {ì¢…ëª©ì½”ë“œ: ì¢…ëª©ëª…}ìœ¼ë¡œ ë³€í™˜
    return {v: k for k, v in stock_list.items()}


def _get_available_tabs() -> list:
    """ì‚¬ìš© ê°€ëŠ¥í•œ íƒ­ ëª©ë¡"""
    market = st.session_state.get('current_market', 'KR')
    
    if market == "US":
        return [
            "ðŸŽ¯ íˆ¬ìž ì»¨íŠ¸ë¡¤ ì„¼í„°",
            "ðŸ“Š ë‹¨ì¼ ì¢…ëª© ë¶„ì„",
            "ðŸ”€ ë‹¤ì¤‘ ì¢…ëª© ë¹„êµ",
            "â­ ê´€ì‹¬ ì¢…ëª©",
            "ðŸ“° ë‰´ìŠ¤ ê°ì„± ë¶„ì„",
            "ðŸ¤– AI ì˜ˆì¸¡",
            "â®ï¸ ë°±í…ŒìŠ¤íŒ…",
            "ðŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”",
            "âš ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬",
            "ðŸ¥ ì‹œìž¥ ì²´ë ¥ ì§„ë‹¨",
            "ðŸ”¥ Market Buzz",
            "ðŸ’Ž íŒ©í„° íˆ¬ìž",
            "ðŸ‘¤ íˆ¬ìž ì„±í–¥",
            "ðŸŒ… AI ìŠ¤í¬ë¦¬ë„ˆ"
        ]
    else:
        return [
            "ðŸŽ¯ íˆ¬ìž ì»¨íŠ¸ë¡¤ ì„¼í„°",
            "ðŸ”´ ì‹¤ì‹œê°„ ì‹œì„¸",
            "ðŸ“Š ë‹¨ì¼ ì¢…ëª© ë¶„ì„",
            "ðŸ”€ ë‹¤ì¤‘ ì¢…ëª© ë¹„êµ",
            "â­ ê´€ì‹¬ ì¢…ëª©",
            "ðŸ“° ë‰´ìŠ¤ ê°ì„± ë¶„ì„",
            "ðŸ¤– AI ì˜ˆì¸¡",
            "â®ï¸ ë°±í…ŒìŠ¤íŒ…",
            "ðŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”",
            "âš ï¸ ë¦¬ìŠ¤í¬ ê´€ë¦¬",
            "ðŸ¥ ì‹œìž¥ ì²´ë ¥ ì§„ë‹¨",
            "ðŸ”¥ Market Buzz",
            "ðŸ’Ž íŒ©í„° íˆ¬ìž",
            "ðŸ‘¤ íˆ¬ìž ì„±í–¥",
            "ðŸŒ… AI ìŠ¤í¬ë¦¬ë„ˆ"
        ]


def _get_chat_service() -> ChatService:
    """ChatService ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì„¸ì…˜ ë¡œë“œ"""
    
    # session_stateì—ì„œ API í‚¤ í™•ì¸ (ì‚¬ìš©ìžê°€ UIì—ì„œ ìž…ë ¥í•œ í‚¤)
    user_api_key = st.session_state.get('gemini_api_key', None)
    
    # API í‚¤ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ ì„œë¹„ìŠ¤ê°€ ì—†ìœ¼ë©´ ìž¬ìƒì„±
    if 'chat_service' not in st.session_state or \
       st.session_state.get('_last_api_key') != user_api_key:
        
        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ì‚¬ìš©ìž ìž…ë ¥ í‚¤ ìš°ì„ )
        llm_client = GeminiClient(api_key=user_api_key)
        
        if not llm_client.is_available():
            logger.warning("[ChatService] Gemini unavailable, using Mock")
            llm_client = MockLLMClient()
        
        # Phase E: ActionExecutor ìƒì„±
        stock_listing = _get_stock_listing()
        available_tabs = _get_available_tabs()
        
        action_executor = ActionExecutor(
            stock_listing=stock_listing,
            available_tabs=available_tabs
        )
        
        service = ChatService(llm_client, action_executor=action_executor)
        service.start_session()
        st.session_state.chat_service = service
        st.session_state._last_api_key = user_api_key
        
    return st.session_state.chat_service


def _extract_context() -> ContextData:
    """
    í˜„ìž¬ Session Stateì—ì„œ ContextData ì¶”ì¶œ
    """
    market = st.session_state.get('current_market', 'KR')
    selected_tab = st.session_state.get('active_tab_name', "ì•Œ ìˆ˜ ì—†ìŒ")
    available_tabs = _get_available_tabs()
    
    context = ContextData(
        tab_name=selected_tab,
        market=market,
        available_tabs=available_tabs,
        user_id=st.session_state.get('user_id', 'default_user')
    )
    
    # ë‹¨ì¼ ì¢…ëª© ë¶„ì„ ë°ì´í„°
    if selected_tab == "ðŸ“Š ë‹¨ì¼ ì¢…ëª© ë¶„ì„":
        if 'ticker_code' in st.session_state:
            context.active_ticker = st.session_state.ticker_code
            context.active_stock_name = st.session_state.get('stock_name')
            
            # AI ë¦¬í¬íŠ¸ ìš”ì•½
            if 'ai_report' in st.session_state:
                report = st.session_state.ai_report
                if hasattr(report, 'summary'):
                     context.ai_report_summary = report.summary
    
    # ìŠ¤í¬ë¦¬ë„ˆ ê²°ê³¼
    elif selected_tab == "ðŸŒ… AI ìŠ¤í¬ë¦¬ë„ˆ":
        if 'screener_picks' in st.session_state:
            picks = st.session_state.screener_picks
            context.screener_results = [
                {
                    "stock_name": p.stock_name,
                    "ticker": p.ticker,
                    "ai_score": p.ai_score,
                    "reason": p.reason,
                    "current_price": p.current_price
                }
                for p in picks
            ]
            
    # í¬íŠ¸í´ë¦¬ì˜¤
    elif selected_tab == "ðŸ’¼ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”":
        if 'portfolio_data' in st.session_state:
            context.portfolio_summary = st.session_state.portfolio_data
            
    return context


def _handle_action_result(result: Optional[ActionExecutionResult]):
    """
    Phase E: ActionExecutionResultë¥¼ ì²˜ë¦¬í•˜ì—¬ UI ìƒíƒœ ì—…ë°ì´íŠ¸
    Clean Architecture: Presentation Layerì—ì„œë§Œ UI ì¡°ìž‘
    """
    if not result or not result.success or not result.redirect_needed:
        return
    
    action_type = result.action.action_type
    data = result.data or {}
    
    if action_type == 'switch_tab':
        tab_name = data.get('tab_name')
        if tab_name:
            st.session_state.pending_tab = tab_name
            logger.info(f"[ActionHandler] Set pending_tab: {tab_name}")
    
    elif action_type == 'select_stock':
        ticker = data.get('ticker')
        name = data.get('name')
        target_tab = data.get('target_tab', 'ðŸ“Š ë‹¨ì¼ ì¢…ëª© ë¶„ì„')
        
        if ticker:
            st.session_state.ticker_code = ticker
            st.session_state.stock_name = name
            st.session_state.pending_tab = target_tab
            logger.info(f"[ActionHandler] Select stock: {name}({ticker})")
    
    elif action_type == 'run_screener':
        tab_name = data.get('tab_name', 'ðŸŒ… AI ìŠ¤í¬ë¦¬ë„ˆ')
        st.session_state.pending_tab = tab_name
        # ìŠ¤í¬ë¦¬ë„ˆ ê²°ê³¼ê°€ ìžˆìœ¼ë©´ ì €ìž¥
        if 'picks' in data:
            st.session_state.pending_screener_picks = data['picks']
        logger.info(f"[ActionHandler] Run screener, switch to: {tab_name}")


def _test_api_key(api_key: str) -> tuple[bool, str]:
    """
    API í‚¤ ì—°ê²° í…ŒìŠ¤íŠ¸
    
    Returns:
        (success: bool, message: str)
    """
    if not api_key or len(api_key) < 20:
        return False, "API í‚¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤"
    
    try:
        import google.generativeai as genai
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash')
        response = model.generate_content("Test")
        
        if response and response.text:
            return True, "ì—°ê²° ì„±ê³µ! (gemini-2.0-flash ì‚¬ìš©)"
        else:
            return False, "API ì‘ë‹µ ì—†ìŒ"
            
    except ImportError:
        return False, "google-generativeai ë¯¸ì„¤ì¹˜"
    except Exception as e:
        error_msg = str(e)
        
        if "404" in error_msg and "models/" in error_msg:
            fallbacks = ['gemini-2.0-flash', 'gemini-2.0-flash-lite', 'gemini-flash-latest', 'gemini-2.5-flash']
            for model_name in fallbacks:
                try:
                    m = genai.GenerativeModel(model_name)
                    res = m.generate_content("Test")
                    if res and res.text:
                        return True, f"ì—°ê²° ì„±ê³µ! ({model_name} ì‚¬ìš©)"
                except:
                    continue

            try:
                available = list(genai.list_models())
                model_list = ", ".join([m.name.split('/')[-1] for m in available if 'generateContent' in m.supported_generation_methods])
                if not model_list:
                    model_list = "ì—†ìŒ"
                return False, f"ëª¨ë¸ 404. ì‚¬ìš© ê°€ëŠ¥: {model_list[:100]}"
            except Exception as list_err:
                return False, f"ëª¨ë¸ 404 & ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨"
        
        if "API_KEY_INVALID" in error_msg or "invalid" in error_msg.lower():
            return False, "ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤"
        elif "quota" in error_msg.lower():
            return False, "API í• ë‹¹ëŸ‰ ì´ˆê³¼"
        elif "permission" in error_msg.lower():
            return False, "ê¶Œí•œ ì˜¤ë¥˜"
        else:
            logger.error(f"API key test failed: {e}")
            return False, f"ì˜¤ë¥˜: {error_msg[:100]}"


def render_sidebar_chat():
    """ì‚¬ì´ë“œë°” ì±—ë´‡ ë Œë”ë§"""
    
    st.sidebar.markdown("---")
    st.sidebar.subheader("ðŸ¤– AI íˆ¬ìž ë¹„ì„œ")
    
    # 0-1. í˜„ìž¬ API ìƒíƒœ í‘œì‹œ
    current_client = GeminiClient(api_key=st.session_state.get('gemini_api_key'))
    
    if current_client.is_available():
        st.sidebar.success("âœ… Gemini API ì—°ê²°ë¨")
    else:
        st.sidebar.info("ðŸ”„ MockLLM ì‚¬ìš© ì¤‘ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)")
    
    # 0-2. API í‚¤ ì„¤ì • UI (Geminiê°€ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•  ë•Œë§Œ í‘œì‹œ)
    temp_client = GeminiClient(api_key=st.session_state.get('gemini_api_key'))
    
    if not temp_client.is_available():
        with st.sidebar.expander("âš™ï¸ API í‚¤ ì„¤ì •", expanded=True):
            st.warning("âš ï¸ **ë³´ì•ˆ ì£¼ì˜**: ê°œì¸ ì‚¬ìš©ë§Œ ê¶Œìž¥")
            st.caption("ðŸ” API í‚¤ëŠ” ë¸Œë¼ìš°ì € ì„¸ì…˜ì—ë§Œ ì €ìž¥ë©ë‹ˆë‹¤ (ìž„ì‹œ)")
            
            api_key_input = st.text_input(
                "API Key",
                type="password",
                value=st.session_state.get('gemini_api_key', ''),
                key="api_key_input",
                placeholder="AIzaSy...",
                help="Google AI Studioì—ì„œ ë°œê¸‰ë°›ì€ API í‚¤"
            )
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("ì ìš© ë° í…ŒìŠ¤íŠ¸", type="primary", use_container_width=True, key="apply_api_key"):
                    if not api_key_input or len(api_key_input) < 10:
                        st.error("âŒ ìœ íš¨í•˜ì§€ ì•Šì€ API í‚¤")
                    else:
                        with st.spinner("ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘..."):
                            success, message = _test_api_key(api_key_input)
                            
                        if success:
                            st.session_state.gemini_api_key = api_key_input
                            st.success(f"âœ… {message}")
                            st.rerun()
                        else:
                            st.error(f"âŒ {message}")
                            st.caption("API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”")
            
            with col2:
                if st.button("ì´ˆê¸°í™”", use_container_width=True):
                    if 'gemini_api_key' in st.session_state:
                        del st.session_state.gemini_api_key
                    st.info("ðŸ”„ MockLLM ì‚¬ìš©")
                    st.rerun()
            
            st.markdown("---")
            st.caption("ðŸ’¡ [API í‚¤ ë°œê¸‰](https://makersuite.google.com/app/apikey)")
            
            with st.expander("ðŸ”’ ë³´ì•ˆ ê¶Œìž¥ì‚¬í•­"):
                st.markdown("""
                **ë°°í¬ í™˜ê²½ì—ì„œëŠ” ë‹¤ìŒ ë°©ë²•ì„ ê¶Œìž¥í•©ë‹ˆë‹¤:**
                
                1. **Streamlit Cloud**: Settings â†’ Secrets
                2. **Docker**: í™˜ê²½ë³€ìˆ˜ (`-e GEMINI_API_KEY=...`)
                3. **ë¡œì»¬ ê°œë°œ**: `.streamlit/secrets.toml`
                
                **UI ìž…ë ¥ì˜ ì œí•œì‚¬í•­**:
                - ë¸Œë¼ìš°ì € ë‹«ìœ¼ë©´ í‚¤ê°€ ì‚¬ë¼ì§
                - ê³µìš© ì»´í“¨í„°ì—ì„œ ì‚¬ìš© ìœ„í—˜
                - ê°œì¸/ë¡œì»¬ ì‚¬ìš©ì—ë§Œ ì í•©
                """)

    # 0-3. ì±„íŒ… ì„¸ì…˜ ì´ˆê¸°í™” ë²„íŠ¼
    if st.sidebar.button("ðŸ’¬ ëŒ€í™” ì´ˆê¸°í™”", use_container_width=True, help="ëŒ€í™” ê¸°ë¡ì„ ì§€ìš°ê³  ì„œë¹„ìŠ¤ë¥¼ ìž¬ì‹œìž‘í•©ë‹ˆë‹¤"):
        if 'chat_service' in st.session_state:
            del st.session_state.chat_service
        if 'chat_history' in st.session_state:
            del st.session_state.chat_history
        st.rerun()
    
    # 1. ì„œë¹„ìŠ¤ & ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
    service = _get_chat_service()
    context = _extract_context()
    
    # 2. ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    messages_container = st.sidebar.container(height=400)
    
    with messages_container:
        for msg in service.current_session.messages:
            with st.chat_message(msg.role):
                st.markdown(msg.content)
    
    # 3. ìž…ë ¥ì°½
    if prompt := st.sidebar.chat_input("ì§ˆë¬¸ì„ ìž…ë ¥í•˜ì„¸ìš”...", key="sidebar_chat_input"):
        # 3.1 ì‚¬ìš©ìž ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ (UI ë°˜ì‘ì„±)
        with messages_container:
            with st.chat_message("user"):
                st.markdown(prompt)
                
        # 3.2 ì‘ë‹µ ìƒì„± (Phase E: Tuple ë°˜í™˜)
        with messages_container:
            with st.chat_message("ai"):
                with st.spinner("ë¶„ì„ ì¤‘..."):
                    response, action_result = service.send_message(prompt, context)
                    st.markdown(response)
        
        # 3.3 Phase E: Action ê²°ê³¼ ì²˜ë¦¬ (UI ìƒíƒœ ì—…ë°ì´íŠ¸)
        _handle_action_result(action_result)
                    
        # 3.4 ë¦¬ë Œë”ë§ (ížˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•´)
        st.rerun()

